# Reddit r/MachineLearning

| | |
|---|---|
| **URL** | [old.reddit.com/r/MachineLearning](https://old.reddit.com/r/MachineLearning/hot/) |
| **Scanned** | 2026-02-03 |
| **Since** | 2026-02-02 |
| **Articles** | 7 |
| **Deduplicated** | true |
| **Removed Count** | 0 |

---

## [P] MichiAI: A 530M Full-Duplex Speech LLM with ~75ms Latency using Flow Matching

- **URL:** https://www.reddit.com/r/MachineLearning/comments/michi-ai-speech-llm/
- **Published:** 2026-02-03
- **Description:** A 530M parameter full-duplex speech LLM achieving ~75ms latency using rectified flow matching. Trained on a single 4090 GPU and a pair of A6000 GPUs, the model uses SmolLM as its backbone and reaches fluency on just 5k hours of audio data.
- **Relevance:** Demonstrates cutting-edge LLM development with speech capabilities, showcasing efficient model architecture design and novel training techniques for multimodal LLMs.

## [D] Where is modern geometry actually useful in machine learning?

- **URL:** https://www.reddit.com/r/MachineLearning/comments/geometry-ml/
- **Published:** 2026-02-02 or 2026-02-03
- **Description:** Discussion exploring the practical application of modern geometry and topology concepts (manifolds, differential forms, connections, curvature, Lie groups) in contemporary machine learning. The author studied "The Geometry of Physics" and seeks guidance on which geometric ideas have actually influenced model and optimizer design beyond theoretical settings.
- **Relevance:** Relevant to understanding fundamental ML theory and architectural innovations that could influence next-generation model designs.

## [D] Optimal Transport for ML

- **URL:** https://www.reddit.com/r/MachineLearning/comments/optimal-transport-ml/
- **Published:** 2026-02-03
- **Description:** Discussion seeking resources for learning optimal transport theory applied to machine learning, with specific requests for simplified explanations beyond "Computational Optimal Transport" textbook.
- **Relevance:** Covers mathematical foundations relevant to modern ML optimization and training techniques.

## [P] PerpetualBooster v1.1.2: GBM without hyperparameter tuning, now 2x faster with ONNX/XGBoost support

- **URL:** https://www.reddit.com/r/MachineLearning/comments/perpetual-booster/
- **Published:** 2026-02-02
- **Description:** Release of PerpetualBooster v1.1.2, a gradient boosting machine written in Rust that eliminates hyperparameter tuning. Features 2x performance improvement, ONNX support, XGBoost interoperability, zero-copy Polars integration, and Python 3.14 support. Shows 100x wall-time speedup compared to LightGBM + Optuna.
- **Relevance:** Represents significant advancement in ML infrastructure and tooling for practical machine learning applications.

## [D] KL Divergence is not a distance metric. It's a measure of inefficiency.

- **URL:** https://www.reddit.com/r/MachineLearning/comments/kl-divergence/
- **Published:** 2026-02-03
- **Description:** Deep dive discussion on KL divergence fundamentals, explaining the asymmetry between forward KL (zero-avoiding, mean-seeking) and reverse KL (zero-forcing, mode-seeking), with implications for model training stability and variance reduction techniques using control variates.
- **Relevance:** Provides theoretical insights into optimization dynamics relevant to training modern LLMs and generative models.

## [D] Your pet peeves in ML research?

- **URL:** https://www.reddit.com/r/MachineLearning/comments/ml-pet-peeves/
- **Published:** 2026-02-03
- **Description:** Community discussion on frustrations in academic machine learning research environment and suggestions for improvement.
- **Relevance:** Captures researcher perspectives on current ML research ecosystem challenges and opportunities.

## [D] New interesting AI papers exploration service

- **URL:** https://www.reddit.com/r/MachineLearning/comments/ai-papers-service/
- **Published:** 2026-02-03
- **Description:** Discussion asking for recommendations on tools to explore interesting AI papers in 2026, referencing the legacy ArXiv Sanity service.
- **Relevance:** Highlights community interest in recent AI paper discoveries and research trends.

---

**Note:** Post URLs are reconstructed based on post titles as exact URLs were not fully visible in the page content. The Reddit content experienced some truncation; additional relevant posts may exist beyond what was captured in this scan.
