# Statement on the Comments from Secretary of War Pete Hegseth

| | |
|---|---|
| **Source** | Anthropic |
| **URL** | [anthropic.com/news/statement-comments-secretary-war](https://www.anthropic.com/news/statement-comments-secretary-war) |
| **Researched** | 2026-02-27 |

## Overview

Anthropic publicly disputed the Department of War's designation of the company as a "supply chain risk," arguing the action exceeds statutory authority and mischaracterizes two refused use cases. The company plans legal challenge while maintaining it can support legitimate national security objectives without compromising on autonomous weapons and domestic surveillance restrictions.

## Key Points

- **Supply Chain Risk Designation**: Department of War declared Anthropic a supply chain risk—unprecedented for a US company, historically reserved for adversaries. Anthropic contests this as beyond Secretary's statutory authority under 10 USC 3252.

- **Narrow Scope Interpretation**: Anthropic argues the designation legally affects only Department of War contracts, not Claude's use across commercial applications or other federal agencies. Individual customers remain unaffected.

- **Two Refused Exceptions**: Anthropic declined to permit mass domestic surveillance of Americans and fully autonomous weapons systems. Company cites inadequate reliability of current AI models for autonomous lethal decision-making and fundamental rights violations.

- **National Security vs. Ethical Boundaries**: Anthropic positions itself as willing to support legitimate defense missions while maintaining non-negotiable safety guardrails. The company contends these refusals haven't impeded any actual government mission.

## Technical Details

The legal dispute centers on interpretation of federal procurement law (10 USC 3252), which governs supply chain restrictions for Department of War contracts. Anthropic's position: the Secretary's authority doesn't extend to blanket commercial restrictions or other agencies' use of the same AI system.

**Risk Assessment Gap**: The company implicitly argues current LLMs lack the reliability guarantees required for autonomous weapons targeting decisions—a technical limitation rather than policy choice.

## Implications

**For practitioners building AI systems for government**:
- Regulatory pressure is increasing on constitutional and ethical constraints in military/national security applications
- Supply chain designations now weaponize policy disagreements between vendors and agencies—expect more precedent-setting actions
- Clear separability of commercial and military deployments matters legally; architecture decisions may need to reflect this

**For AI policy**:
- This marks escalation beyond contract restrictions to supply chain stigmatization for refusing specific capabilities
- Autonomous weapons and surveillance remain flashpoints where vendor ethics directly conflict with government demand
- Courts will test whether AI vendors have enforceable boundaries independent of government procurement leverage

**Strategic positioning**: Companies must decide upfront whether refusal to build certain capabilities is worth supply chain stigma and legal costs. Anthropic's stance trades government revenue/contracts for brand positioning and legal defensibility.

## Sources

- [Anthropic News - Statement on Secretary of War Comments](https://www.anthropic.com/news/statement-comments-secretary-war) - Official company response to supply chain risk designation