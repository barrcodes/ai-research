# Reddit r/LocalLLaMA

| | |
|---|---|
| **URL** | [old.reddit.com/r/LocalLLaMA](https://old.reddit.com/r/LocalLLaMA/top/?t=week) |
| **Scanned** | 2026-02-27 |
| **Since** | 2026-02-23 |
| **Articles** | 8 |
| **Deduplicated** | true |
| **Removed Count** | 0 |

---

## Anthropic: "We've identified industrial-scale distillation attacks on our models by DeepSeek, Moonshot AI, and MiniMax."
- **URL:** https://old.reddit.com/r/LocalLLaMA/comments/[distillation-attack-post]
- **Published:** 2026-02-23 (4 days ago)
- **Upvotes/Comments:** 4610 upvotes, 855 comments
- **Description:** Anthropic announced discovery of industrial-scale model distillation attacks from Chinese AI labs including DeepSeek, Moonshot AI, and MiniMax attempting to extract Claude's capabilities into their open models.
- **Relevance:** Critical discussion on model distillation, open-source model development, and competitive dynamics between closed and open-source AI models.

## Distillation when you do it. Training when we do it.
- **URL:** https://old.reddit.com/r/LocalLLaMA/comments/[distillation-meme-post]
- **Published:** 2026-02-23 (4 days ago)
- **Upvotes/Comments:** 3340 upvotes, 203 comments
- **Description:** Community meme responding to Anthropic's distillation announcement, highlighting perceived double standards in how different organizations approach knowledge transfer from frontier models.
- **Relevance:** Community response to model distillation practices and open-source vs. closed-source dynamics.

## Qwen3.5-35B-A3B is a gamechanger for agentic coding.
- **URL:** https://old.reddit.com/r/LocalLLaMA/comments/[qwen35-agentic-post]
- **Published:** 2026-02-24 (3 days ago)
- **Upvotes/Comments:** 1063 upvotes, 356 comments
- **Description:** Discussion post about Qwen3.5-35B model's exceptional performance in agentic coding tasks, highlighting it as a breakthrough for local coding assistant applications.
- **Relevance:** New Qwen model release and capabilities for AI coding assistants, a key local LLM development.

## New Qwen3.5 models spotted on qwen chat
- **URL:** https://old.reddit.com/r/LocalLLaMA/comments/[qwen35-spotted-post]
- **Published:** 2026-02-24 (3 days ago)
- **Upvotes/Comments:** 646 upvotes, 195 comments
- **Description:** Announcement of new Qwen3.5 models discovered on the Qwen chat platform, indicating recent model releases from the Qwen family.
- **Relevance:** New model release announcement, important for tracking open-source LLM development.

## Qwen/Qwen3.5-122B-A10B
- **URL:** https://huggingface.co/Qwen/Qwen3.5-122B-A10B
- **Published:** 2026-02-24 (3 days ago)
- **Upvotes/Comments:** 596 upvotes, 128 comments
- **Description:** Release of the Qwen3.5-122B-A10B model on Hugging Face, a large-scale quantized variant of the Qwen3.5 family optimized for inference.
- **Relevance:** New large model release with quantization optimization (A10B indicates 10-bit quantization), crucial for local model deployment and inference.

## Qwen/Qwen3.5-35B-A3B
- **URL:** https://huggingface.co/Qwen/Qwen3.5-35B-A3B
- **Published:** 2026-02-24 (3 days ago)
- **Upvotes/Comments:** 550 upvotes, 181 comments
- **Description:** Release of the Qwen3.5-35B-A3B model, a mid-sized quantized variant of Qwen3.5 optimized for local inference and agentic applications.
- **Relevance:** New quantized model release designed for local deployment and coding tasks, directly relevant to the local LLM ecosystem.

## American closed models vs Chinese open models is becoming a problem.
- **URL:** https://old.reddit.com/r/LocalLLaMA/comments/[closed-vs-open-post]
- **Published:** 2026-02-26 (1 day ago)
- **Upvotes/Comments:** 660 upvotes, 579 comments
- **Description:** Discussion about the competitive dynamics between American closed-source models (Claude, GPT-4) and Chinese open-source models (Qwen, DeepSeek), exploring implications for model availability and licensing.
- **Relevance:** Strategic discussion on open vs. closed-source model landscape, model releases, and competitive positioning in the AI industry.

## PewDiePie fine-tuned Qwen2.5-Coder-32B to beat ChatGPT 4o on coding benchmarks.
- **URL:** https://www.youtube.com/watch?v=aV4j5pXLP-I&feature=youtu.be
- **Published:** 2026-02-27 (12 hours ago)
- **Upvotes/Comments:** 550 upvotes, 110 comments
- **Description:** Notable experiment showing fine-tuning of Qwen2.5-Coder-32B achieving superior performance to ChatGPT-4o on coding benchmarks, demonstrating the viability of optimizing open models for specific tasks.
- **Relevance:** Practical demonstration of model fine-tuning, coding assistant optimization, and open-source model capability improvements.
