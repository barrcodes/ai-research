# HuggingFace Blog

| | |
|---|---|
| **URL** | [huggingface.co/blog](https://huggingface.co/blog) |
| **Scanned** | 2026-02-02 |
| **Since** | 2026-01-31 |
| **Articles** | 7 |

---

## We got Claude to teach open models how to write CUDA kernels!
- **URL:** https://huggingface.co/blog/upskill
- **Published:** 2026-01-28
- **Description:** Introduces `upskill`, a tool for generating and evaluating agent skills that enable open-source and smaller models to learn complex tasks like writing CUDA kernels. Demonstrates a three-step process using Claude Opus 4.5 as a teacher model to transfer capabilities to other models through skill files.
- **Relevance:** Directly relevant to Claude AI capabilities, agentic patterns, coding assistants, and tool transfer between LLMs. Showcases Claude Opus building specialized coding skills.

## Introducing Daggr: Chain apps programmatically, inspect visually
- **URL:** https://huggingface.co/blog/daggr
- **Published:** 2026-01-29
- **Description:** Announces Daggr, an open-source Python library for building AI workflows that connect Gradio apps, ML models, and custom functions with automatic visual canvas generation. Supports interactive debugging, state persistence, and integration with HuggingFace inference providers.
- **Relevance:** Relevant to AI tools and agentic patterns. Daggr enables building complex AI pipelines and agent workflows with integrated debugging capabilities.

## Introducing NVIDIA Cosmos Policy for Advanced Robot Control
- **URL:** https://huggingface.co/blog/nvidia/cosmos-policy-for-robot-control
- **Published:** 2026-01-29
- **Description:** Introduces Cosmos Policy, a state-of-the-art robot control model that fine-tunes NVIDIA's Cosmos Predict-2 foundation model for manipulation tasks. Achieves 98.5% success on LIBERO benchmark and 67.1% on RoboCasa with minimal training data.
- **Relevance:** Relevant to LLM infrastructure and advanced AI capabilities. Demonstrates foundation models applied to robotics and real-world deployment of specialized AI systems.

## Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective
- **URL:** https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl
- **Published:** 2026-01-27
- **Description:** Documents LinkedIn's technical journey enabling agentic reinforcement learning training for GPT-OSS model. Details critical fixes for MoE log-probability computation, FlashAttention v3 compatibility, and memory optimizations that enabled stable training on 16 H200 nodes.
- **Relevance:** Highly relevant to agentic patterns, AI infrastructure, and LLM training. Addresses practical challenges in training open models for multi-step agent decision-making with tool use.

## Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek
- **URL:** https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2
- **Published:** 2026-01-27
- **Description:** Examines architectural and design trends in China's open-source AI landscape post-DeepSeek, identifying key patterns including MoE adoption as default architecture, multimodal competition, and strategic emphasis on efficient smaller models.
- **Relevance:** Relevant to LLM architectures and AI infrastructure developments. Provides landscape analysis of competitive architectural choices and model design trends in open-source AI.

## Fine-Tuning FunctionGemma on TPU to Create a Virtual Fitness Coach in 10 Minutes, $0.50
- **URL:** https://huggingface.co/blog/tengomucho/finetune-a-fitness-coach
- **Published:** 2026-02-02
- **Description:** Demonstrates rapid, cost-effective fine-tuning of Google's FunctionGemma (270M parameters) on TPU for function-calling applications. Achieves 6x training speedup through SPMD initialization, FSDP v2, and static tensor shapes, reducing training time to ~10 minutes at $0.50 cost.
- **Relevance:** Relevant to coding assistants and AI tools with function-calling capabilities. Shows practical techniques for fine-tuning smaller LLMs for specialized function-calling tasks.

## Alyah: Toward Robust Evaluation of Emirati Dialect Capabilities in Arabic LLMs
- **URL:** https://huggingface.co/blog/tiiuae/emirati-benchmarks
- **Published:** 2026-01-27
- **Description:** Introduces Alyah benchmark for evaluating LLM capabilities in Emirati dialect across multiple dimensions. Provides systematic evaluation framework for assessing specialized linguistic capabilities in language models.
- **Relevance:** Relevant to LLM benchmarking and evaluation methodologies. Represents recent work on specialized evaluation frameworks for language model capabilities.
