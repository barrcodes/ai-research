---
source: Anthropic
url: https://www.anthropic.com/news
scanned_at: 2026-02-24T00:00:00Z
article_count: 1
fetch_method: unknown
deduplicated: true
removed_count: 0
---

## Detecting and Preventing Distillation Attacks
- url: https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks
- published: 2026-02-23
- description: Anthropic disclosed that three major AI labs (DeepSeek, Moonshot, and MiniMax) conducted industrial-scale campaigns to extract Claude's capabilities through model distillation, generating over 16 million unauthorized exchanges via approximately 24,000 fraudulent accounts.
- relevance: Directly relevant to Claude LLM development and security. Discusses unauthorized attempts to distill Claude's agentic reasoning, tool use, and coding capabilitiesâ€”core LLM development topics. Also addresses AI infrastructure security and competitive dynamics in frontier LLM development.
